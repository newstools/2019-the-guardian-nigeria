 Photo: PEXELS  According to Facebook, in regulation, all stakeholders including users, organisation, the private sector, and even the government have got roles to play. Head of Public Policy, Facebook Southern African Development Community, Emilar Gandhi, noted that regulation is important but should be pro-innovation. According to her, it is not a yes or no answer, but there should be self-regulation as well. Speaking at a Content Workshop for journalists in some African countries, Gandhi reminded us that social media doesn’t exist in abstract, isolation, “meaning that media, technology, and others should also be looked into. “Third-party fact-checking is also very important, we are taking steps to tackle false news on Facebook, it is a responsibility we take seriously. “It is important to know that misinformation is a problem and that is why third-party fact-checking is very important.’’ She stressed that innovation should be one that will spur further innovation and encourage content creation at its best. Gandhi added that Africa has amazing talents in the continent, and that was why Facebook was doing everything in its power to improve Internet access in African countries. This Facebook’s submission came on the heels of plans by the Federal Government of Nigeria to regulate the social media space. The Minister of Information, Tourism and Development, Lai Mohammed, informed last week that it has become necessary for the government to sanitise the social media space, especially against the spread of fake news, and other abuses on the platforms. Meanwhile, as part of measures to fight the scourge of hate speech, Facebook has deployed over 35,000 experts to review contents on its platform. Aside hate speech, which it said has become a major issue globally, Facebook said the content review team is also looking out for posts that constitute a danger to the platform users with a view to removing them. Content Policy Associate Manager, Facebook sub-Sahara Africa, Fadzai Madzingira, said the experts on daily basis review contents in 50 languages. Explaining what constitutes hate speech on the platform, and which are likely to be pulled down by the monitoring team, Madzingira said: “We define hate speech as a direct attack on people based on what we call protected characteristics, race, ethnicity, religious affiliation, sex, and serious disability among others. “Talking on attacks, we define it as violent or dehumanising speech, statement of inferiority, and calls for exclusion or segregation.” She said attacks were separated into three tiers, noting that the first tier consists of content targeted at dehumanising a person or a group of people on the basis of their immigration status. According to Madzingira, the second tier targets a person or group of people based on their physical deficiencies, intellectual capacity and mental health among others. “The third tier focuses on calls for segregation, the explicit exclusion of the right of a person or group of people to participate in politics, economic entitlement and opportunity to gain access to spaces and social services,” she said. Furthermore, Gandhi said the company’s security team that liaises with law enforcement authorities to ensure safety of Facebook users.
According to her, if there is any post that poses an imminent danger either the poster or other users, the team reports such to the law enforcement authorities to prevent harm. To enable commenting and other interactive features, please switch to the more advanced .